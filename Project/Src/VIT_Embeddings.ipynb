{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrfVc0HdGtYB",
        "outputId": "2252c95b-33a8-463c-c381-321615bca56f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install facenet-pytorch timm torch torchvision numpy pillow tqdm"
      ],
      "metadata": {
        "id": "mkUfPxYUHXqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from facenet_pytorch import MTCNN\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import timm"
      ],
      "metadata": {
        "id": "QI8hGaiIMNdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/combined_dataset_new\"\n",
        "save_dir = \"/content/deepfake_embedding\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ignG2ZesMTIl",
        "outputId": "51e1aee5-3d6e-43f1-936d-d8c4adcddbef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Face detector\n",
        "mtcnn = MTCNN(image_size=224, margin=20, keep_all=False, device=device)\n",
        "\n",
        "# Vision Transformer model for embeddings\n",
        "vit_model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "vit_model.head = torch.nn.Identity()  # remove classifier head\n",
        "vit_model.to(device)\n",
        "vit_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBkxSKWsMnA-",
        "outputId": "ff15dd92-8e1c-44ed-c816-09500517e6d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionTransformer(\n",
              "  (patch_embed): PatchEmbed(\n",
              "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "    (norm): Identity()\n",
              "  )\n",
              "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "  (patch_drop): Identity()\n",
              "  (norm_pre): Identity()\n",
              "  (blocks): Sequential(\n",
              "    (0): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (1): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (2): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (3): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (4): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (5): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (6): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (7): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (8): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (9): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (10): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (11): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  (fc_norm): Identity()\n",
              "  (head_drop): Dropout(p=0.0, inplace=False)\n",
              "  (head): Identity()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vit_embedding(img_path):\n",
        "    try:\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        face = mtcnn(img)\n",
        "        if face is None:\n",
        "            return None\n",
        "\n",
        "        # Face is already tensor (C,H,W)\n",
        "        face = face.unsqueeze(0).to(device)\n",
        "        face = (face - 0.5) / 0.5  # normalize between -1 and 1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            emb = vit_model(face).cpu().numpy().flatten()\n",
        "        return emb\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {img_path}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "agJrHqt5MuNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = [], []\n",
        "\n",
        "for label_name, label_val in [(\"Real\", 0), (\"Fake\", 1)]:\n",
        "    folder = os.path.join(data_dir, label_name)\n",
        "    if not os.path.exists(folder):\n",
        "        print(f\"++Folder not found: {folder}\")\n",
        "        continue\n",
        "\n",
        "    for img_name in tqdm(os.listdir(folder), desc=f\"Processing {label_name}\"):\n",
        "        img_path = os.path.join(folder, img_name)\n",
        "        if not img_path.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "            continue\n",
        "\n",
        "        emb = get_vit_embedding(img_path)\n",
        "        if emb is not None:\n",
        "            X.append(emb)\n",
        "            y.append(label_val)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Extraction complete!\")\n",
        "print(\"Embeddings shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9SQKzwyMy-m",
        "outputId": "144053b9-12d8-417a-b4b6-18f8fbd6c219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing real: 100%|██████████| 500/500 [06:19<00:00,  1.32it/s]\n",
            "Processing fake: 100%|██████████| 500/500 [07:12<00:00,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extraction complete!\n",
            "Embeddings shape: (838, 768)\n",
            "Labels shape: (838,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(os.path.join(save_dir, \"X_vit_embeddings.npy\"), X)\n",
        "np.save(os.path.join(save_dir, \"y_labels.npy\"), y)\n",
        "print(\"Embeddings saved to:\", save_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvqSTKE4M4kp",
        "outputId": "76e1107c-3ce2-412c-eccb-4eb07e061d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Embeddings saved to: /content/deepfake_embedding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Path where you saved the embeddings\n",
        "save_dir = \"/content/deepfake_embedding\"\n",
        "\n",
        "# Load .npy files\n",
        "X = np.load(f\"{save_dir}/X_vit_embeddings.npy\")\n",
        "y = np.load(f\"{save_dir}/y_labels.npy\")\n",
        "\n",
        "# Check shapes\n",
        "print(\"Embeddings shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)\n",
        "\n",
        "# View a few embeddings\n",
        "print(\"\\nSample Embedding (first row):\\n\", X[0])\n",
        "print(\"\\nLabel for this embedding:\", y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDqK6ouyM_wL",
        "outputId": "b775ca99-5600-4fb5-867c-db108b781183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: (838, 768)\n",
            "Labels shape: (838,)\n",
            "\n",
            "Sample Embedding (first row):\n",
            " [ 2.49818134e+00 -3.06579518e+00 -1.56503034e+00 -3.53825986e-01\n",
            " -3.20551664e-01 -1.18795419e+00  1.92895365e+00  2.63427210e+00\n",
            "  1.20990232e-01  3.40338796e-01  8.44277978e-01 -1.50059378e+00\n",
            "  1.46957129e-01 -1.27068424e+00 -8.66069674e-01  4.56599444e-01\n",
            "  6.53088391e-01 -1.26802838e+00 -1.56395924e+00  6.01584077e-01\n",
            "  1.30887938e+00  1.38220215e+00 -7.86968887e-01 -1.53597808e+00\n",
            " -1.00858104e+00  6.88783705e-01  7.35350791e-03  8.92337859e-02\n",
            " -4.15933758e-01 -1.82200587e+00  2.04298735e+00 -1.91502631e+00\n",
            "  8.89839947e-01 -2.04025340e+00 -4.38666135e-01  2.11892319e+00\n",
            " -6.50086284e-01  1.99009478e+00 -1.15953898e+00 -1.45665157e+00\n",
            "  1.04546928e+00  2.04804271e-01  1.44774318e-01 -2.01874399e+00\n",
            " -2.60067511e+00 -1.23651636e+00 -3.77473402e+00 -8.22797358e-01\n",
            " -2.19426855e-01  1.13229893e-01 -3.36363971e-01  1.18089139e+00\n",
            " -1.95771599e+00  2.18909606e-01 -8.85927260e-01  1.88188028e+00\n",
            " -5.30875981e-01  1.17009747e+00  4.64145206e-02  1.99900711e+00\n",
            "  1.15195131e+00 -6.04556262e-01 -7.48024285e-01 -1.74690783e+00\n",
            "  1.42827439e+00  1.24404025e+00 -8.45857620e-01 -1.95508957e+00\n",
            " -3.76611382e-01  1.58479428e+00 -2.19843864e+00 -5.08089721e-01\n",
            "  1.23442745e+00  1.05236568e-01 -9.60835218e-01  2.38722920e+00\n",
            " -1.06897950e+00 -1.54757714e+00 -4.92226869e-01 -1.88623801e-01\n",
            "  6.58713698e-01  3.03374350e-01  1.42029250e+00  1.64869092e-02\n",
            "  3.11069787e-01 -6.70752721e-03 -2.42236763e-01 -8.41606140e-01\n",
            " -1.50538934e-02 -3.04998899e+00 -1.69748461e+00  4.47098541e+00\n",
            " -1.44671822e+00  1.17032695e+00  9.94429946e-01  1.54218495e-01\n",
            "  7.41177917e-01 -2.92057276e-01 -2.74078679e+00 -7.48317301e-01\n",
            "  2.06300330e+00  1.19664955e+00 -1.96141922e+00 -2.51390529e+00\n",
            " -2.44053411e+00  2.54057050e+00  5.71650326e-01  1.18450773e+00\n",
            " -1.20803797e+00  3.88055801e-01  5.22235930e-01  1.99410886e-01\n",
            "  8.54648352e-01  4.50877756e-01  8.67869377e-01 -5.35790443e-01\n",
            " -8.08549523e-02 -5.02883077e-01 -3.17659402e+00  1.11150280e-01\n",
            "  5.48404574e-01 -1.77922833e+00 -1.83446872e+00 -1.50764570e-01\n",
            "  7.38319337e-01  2.09182596e+00 -7.04532623e-01 -2.05049944e+00\n",
            "  9.19109106e-01  7.02911079e-01 -3.97163630e-01 -1.46821570e+00\n",
            " -1.45462155e-01 -3.89245212e-01 -3.61453205e-01 -2.74551719e-01\n",
            " -1.07995665e+00  1.77515960e+00  4.67528999e-01  1.28351307e+00\n",
            "  4.80699587e+00  9.47351396e-01 -1.54255795e+00  1.29371688e-01\n",
            "  1.03957260e+00 -1.24092519e+00 -7.53975689e-01  1.71943533e+00\n",
            "  9.88028109e-01 -2.76183188e-01 -1.44296050e+00 -7.02686727e-01\n",
            "  3.83169323e-01  1.63819385e+00 -2.80581522e+00  1.10857822e-01\n",
            " -4.38618124e-01  3.39245647e-01  5.93700409e+00  7.26323500e-02\n",
            "  1.20849812e+00  3.29440534e-01 -1.69386312e-01  1.31710982e+00\n",
            "  8.64855886e-01 -1.86146152e+00 -1.74708104e+00 -3.98073882e-01\n",
            " -1.27758479e+00 -1.21940017e+00  6.95049167e-01  3.04592204e+00\n",
            " -4.44163752e+00 -1.90477383e+00 -3.44023854e-01  1.73258340e+00\n",
            "  4.00345057e-01  2.53538877e-01 -3.61526042e-01  1.51085401e+00\n",
            " -2.41513997e-01 -1.12706602e+00 -6.15695834e-01 -5.51537156e-01\n",
            " -3.91971692e-02 -7.16594338e-01  4.54423368e-01  5.91155291e-01\n",
            "  2.68943638e-01 -1.18436202e-01  2.55663252e+00 -6.80997968e-01\n",
            " -1.63532531e+00 -4.98964131e-01  1.40259445e+00 -6.98756576e-01\n",
            " -1.62215531e+00 -8.16381335e-01  1.22228801e+00 -1.77285337e+00\n",
            "  1.19443841e-01 -3.57355565e-01 -8.58488321e-01 -4.87398595e-01\n",
            "  1.17310178e+00 -3.61745358e-01  1.28766906e+00  5.88206314e-02\n",
            "  1.48302162e+00 -1.45827591e+00 -8.85872781e-01  1.37939858e+00\n",
            "  8.68194401e-01 -1.07349586e+00  9.57946420e-01 -7.01092839e-01\n",
            "  1.38756871e+00 -1.34475744e+00 -3.68668407e-01  1.03894091e+00\n",
            " -2.85503435e+00  8.76309812e-01  2.11152387e+00  3.33830476e-01\n",
            "  2.33999118e-01 -2.42512617e-02  1.29618740e+00 -1.68468022e+00\n",
            "  7.08992064e-01  6.04666293e-01  4.54155952e-01  1.37644753e-01\n",
            " -1.11174953e+00  6.80135965e-01  2.33680797e+00 -1.24614477e+00\n",
            " -1.20485723e+00  1.42773402e+00  1.35661399e+00  4.38997269e-01\n",
            " -5.07215619e-01  7.49508560e-01  2.64447451e+00  2.03415012e+00\n",
            " -8.01704749e-02 -4.07746285e-01 -7.19201744e-01 -1.25711894e+00\n",
            "  2.24088818e-01 -1.25370145e+00 -1.01609170e+00 -5.89231491e-01\n",
            "  3.99546325e-01 -2.85222113e-01  7.26477802e-01 -1.96129286e+00\n",
            "  6.28591251e+00  6.85814476e+00 -5.85709885e-02 -5.72622895e-01\n",
            "  6.07253492e-01  1.93257213e-01 -1.03848958e-02  1.49255133e+00\n",
            "  1.54678929e+00  8.60575497e-01 -1.06955552e+00  2.21303821e+00\n",
            "  1.18533477e-01  1.97832036e+00 -1.83610296e+00 -4.79097068e-01\n",
            " -6.37954697e-02 -1.42659545e+00 -1.20238709e+00 -1.24484098e+00\n",
            "  9.05353832e+00  5.76015115e-01  1.16431549e-01 -1.60169765e-01\n",
            "  1.48297548e+00  2.69252092e-01 -1.33077455e+00  5.64438820e-01\n",
            "  5.18909752e-01 -9.46203530e-01  2.50488615e+00 -4.89231855e-01\n",
            " -8.88939202e-01  5.91599882e-01  4.10277307e-01 -1.70314848e+00\n",
            " -1.23236179e+00  1.00916423e-01  6.28496230e-01 -5.46132267e-01\n",
            "  1.54054737e+00 -1.75406605e-01 -2.40031481e+00 -4.63024259e-01\n",
            " -6.69182658e-01 -2.99094051e-01  2.93621421e+00 -1.97756016e+00\n",
            " -1.06496513e+00  9.17511165e-01 -4.88800496e-01  2.85966367e-01\n",
            "  1.90112662e+00  1.08477235e+00  7.67852068e-01 -8.10043097e-01\n",
            " -1.69079888e+00  7.25058258e-01 -8.47345293e-01 -1.58168912e-01\n",
            " -1.26367223e+00 -5.38391352e-01 -5.57729423e-01  3.64992380e+00\n",
            "  6.67048872e-01 -1.68610454e+00  4.60348129e-01  5.10784507e-01\n",
            " -6.70835748e-02 -3.86356831e+00  8.50276828e-01  1.37703025e+00\n",
            " -2.17906260e+00  7.71653235e-01 -1.11795425e+00 -1.64510816e-01\n",
            " -1.17920280e+00 -5.99748611e-01  2.63881969e+00 -9.92832303e-01\n",
            " -2.15166545e+00  2.03521514e+00 -2.27527809e+00  6.87552154e-01\n",
            " -8.74429524e-01 -2.46197358e-01  1.04984534e+00 -1.97458267e-01\n",
            " -2.10613775e+00  4.74756896e-01 -2.90697432e+00 -7.35680938e-01\n",
            "  8.78435969e-02  9.72443342e-01  7.61773050e-01 -7.17297554e-01\n",
            "  1.83954024e+00  9.21589732e-01  8.24227929e-01  2.27904201e+00\n",
            " -3.94850411e-03  5.16257107e-01  2.43340015e+00  9.03531015e-01\n",
            "  1.57258046e+00  3.60304451e+00 -1.20302069e+00 -1.51667964e+00\n",
            " -1.68184161e+00  1.18799961e+00 -1.53936362e+00  1.65425432e+00\n",
            "  1.22869503e+00 -7.57228911e-01 -6.45713747e-01 -1.77179658e+00\n",
            "  2.52448767e-01 -6.08623803e-01 -2.44167590e+00 -1.08482099e+00\n",
            "  4.05712485e-01  1.67654812e-01  5.26838720e-01 -1.67955816e+00\n",
            "  1.33648968e+00  2.91646957e+00 -1.50313926e+00 -1.35587931e-01\n",
            " -2.75126547e-01  2.10824060e+00  5.58157921e-01  8.54670167e-01\n",
            "  6.90033138e-01 -2.30475807e+00 -2.15981960e-01 -2.50709116e-01\n",
            " -1.31328380e+00  7.67945111e-01 -9.31695402e-01 -4.24351513e-01\n",
            "  4.21136111e-01 -4.05849040e-01 -1.40188694e+00  1.52207017e+00\n",
            "  4.05439585e-01 -2.07282841e-01  7.52331177e-03 -3.64649743e-01\n",
            " -6.52282476e-01 -2.08219886e+00 -1.53898871e+00  1.18083966e+00\n",
            " -2.65524387e+00 -2.00038242e+00  8.68242025e-01  3.46846253e-01\n",
            " -1.31310239e-01 -7.40389228e-01 -1.24022223e-01  1.65910006e+00\n",
            " -2.26329541e+00  3.58545232e+00 -6.64014593e-02 -2.69180119e-01\n",
            "  9.35546681e-02 -2.40168184e-01 -6.20835900e-01  6.08965099e-01\n",
            " -3.24498892e-01  2.04413724e+00 -5.72733819e-01 -5.84259152e-01\n",
            "  1.24370408e+00 -1.09603912e-01 -1.42762506e+00  4.50203449e-01\n",
            "  9.12352026e-01 -5.55783153e-01 -9.53824520e-01  1.37779129e+00\n",
            " -8.94137204e-01  2.01916122e+00 -1.70426798e+00 -2.18468547e-01\n",
            "  1.02331388e+00 -1.44820261e+00  1.23216987e+00 -4.43087697e-01\n",
            " -2.64228463e-01  8.29392433e+00  9.75525200e-01 -1.94969606e+00\n",
            " -1.83113024e-01  2.58632123e-01 -4.92861241e-01  1.52695730e-01\n",
            " -1.69018209e+00  4.04722363e-01 -3.09700298e+00  9.41550970e-01\n",
            "  9.08809423e-01  1.36681092e+00 -1.85279906e+00 -1.63498116e+00\n",
            "  8.20104718e-01  8.47774208e-01 -6.21414185e-01 -2.34289074e+00\n",
            "  1.07591367e+00  1.65487707e+00  8.68760169e-01 -1.92224360e+00\n",
            "  1.18464768e-01 -7.41573930e-01  9.45840836e-01 -3.91463757e+00\n",
            " -1.21678245e+00 -2.79276705e+00  4.58611935e-01  1.81777942e+00\n",
            " -1.62345850e+00 -4.91606206e-01  2.06822027e-02 -6.89582765e-01\n",
            " -1.35734463e+00 -2.55704737e+00  4.28130102e+00 -6.68108761e-01\n",
            "  2.68207598e+00 -1.56831288e+00 -1.49092698e+00 -4.97741438e-02\n",
            " -1.68745518e+00  1.77761421e-01 -3.15105867e+00 -1.54040372e+00\n",
            " -2.00464630e+00 -6.85504973e-02  1.05002141e+00  2.90452510e-01\n",
            "  1.30628252e+00 -2.69785881e+00 -6.61184132e-01 -1.44398224e+00\n",
            " -1.82295796e-02 -2.09531069e+00 -3.65193710e-02  7.56630242e-01\n",
            " -5.65637767e-01 -6.46246254e-01  9.87205982e-01  1.02095321e-01\n",
            " -2.41499281e+00  6.54404736e+00 -3.18776155e+00 -2.88760573e-01\n",
            "  1.25675166e+00  3.22973639e-01  8.93348575e-01 -8.66527081e-01\n",
            " -3.89122963e-01 -1.01160359e+00  3.42492551e-01  8.43427658e-01\n",
            " -1.43457448e+00  9.61114049e-01  2.04643393e+00 -6.66951895e-01\n",
            "  1.21686244e+00  1.50389448e-01  3.81661445e-01 -8.74000549e-01\n",
            " -2.91450739e+00  7.23980665e-01  7.22647095e+00 -2.65959573e+00\n",
            "  2.10409546e+00 -6.11874938e-01  6.95044875e-01  1.41611528e+00\n",
            "  1.10704637e+00  4.09585416e-01 -4.83389795e-01  1.04975915e+00\n",
            "  9.71234500e-01 -3.99729013e-01 -7.67023087e-01 -4.92248327e-01\n",
            "  6.29080772e-01  6.49195850e-01  5.51339567e-01  6.74401641e-01\n",
            "  1.29736692e-01 -9.58558381e-01 -1.31197023e+00 -9.51685071e-01\n",
            "  1.62580025e+00 -8.96442890e-01  9.38272953e-01 -3.53137612e+00\n",
            " -1.40870655e+00  1.87005198e+00 -1.13646779e-02  2.11849570e+00\n",
            " -2.81744933e+00 -3.39712948e-01 -7.83166647e-01  6.42210305e-01\n",
            " -1.71226656e+00 -1.06279302e+00 -9.80629742e-01 -1.59608793e+00\n",
            " -7.77611509e-02  1.16780007e+00  1.08545065e-01 -1.78452468e+00\n",
            "  3.77285552e+00 -7.58886278e-01 -3.23481500e-01  2.48703504e+00\n",
            "  9.77231681e-01 -4.97024059e-01  5.78670561e-01 -1.44811526e-01\n",
            " -1.23752363e-01 -7.24509656e-01  8.50924194e-01  1.15090048e+00\n",
            " -5.17351091e-01 -3.09894115e-01 -3.47915329e-02 -1.07001519e+00\n",
            " -1.81420004e+00  1.27465315e+01 -1.57581949e+00  1.59384513e+00\n",
            " -5.35044372e-02 -3.46828580e+00  1.21028674e+00  6.66527927e-01\n",
            "  3.68082857e+00  7.75925100e-01 -3.00392032e-01  1.17407656e+00\n",
            "  1.06534362e+00 -8.07896078e-01 -7.25832880e-01  2.20898581e+00\n",
            " -2.21254849e+00 -6.84206188e-01 -7.60718137e-02 -2.46066165e+00\n",
            " -2.45518133e-01  1.78068161e+00  1.34288466e+00 -1.73272979e+00\n",
            " -1.23779106e+00  1.63771927e+00 -3.13844532e-02  2.75621135e-02\n",
            " -1.40201449e+00  2.61205912e+00 -3.70127439e-01  1.00841665e+01\n",
            "  2.65568137e-01  2.00683737e+00 -1.25656235e+00 -2.64704490e+00\n",
            "  1.06467271e+00  8.56411338e-01 -1.01708066e+00  2.20722437e-01\n",
            "  8.67873430e-01 -9.15858150e-01 -1.16273093e+00  1.75565982e+00\n",
            " -2.98619624e-02 -4.23879594e-01 -2.84713477e-01  1.18895978e-01\n",
            " -8.49274874e-01  1.90498948e+00  5.37879206e-02  1.74466395e+00\n",
            "  9.91480827e-01  1.18318237e-01  7.40200162e-01  2.00258255e+00\n",
            " -1.68931866e+00  7.90397346e-01 -1.61400843e+00  1.55350184e+00\n",
            " -1.65806726e-01  1.27123162e-01  4.02971476e-01  5.62851489e-01\n",
            " -6.23023510e-01 -1.73329443e-01  1.48981833e+00 -1.05842638e+00\n",
            "  3.67755443e-01  7.42128074e-01  1.98815793e-01  6.33687735e-01\n",
            "  1.41943443e+00  3.50908816e-01  1.21759331e+00  1.21399331e+00\n",
            " -2.98075366e+00  7.06868172e-01 -1.12775230e+00 -6.59282923e-01\n",
            " -1.67877793e+00  3.98217052e-01 -6.52305841e-01  4.23469484e-01\n",
            " -4.06599373e-01 -2.35583365e-01  6.41531408e-01  6.85219228e-01\n",
            "  4.66766268e-01 -1.41701967e-01  4.49867606e-01 -3.91699433e-01\n",
            " -3.95733446e-01 -6.20429039e-01 -2.32307482e+00  7.17959851e-02\n",
            "  1.03519106e+00 -1.18906105e+00 -8.04704249e-01 -3.48263681e-01\n",
            "  6.21778190e-01 -3.08539033e-01  2.06507659e+00 -1.21168756e+00\n",
            "  5.63135445e-01  2.06775665e-01  2.70511508e+00  4.66143247e-03\n",
            "  1.80108595e+00 -1.96404815e+00  1.00337458e+00  4.95599471e-02\n",
            " -1.95124257e+00  2.85850819e-02  1.61039555e+00  4.34200764e-01\n",
            " -1.77009261e+00  1.56336099e-01 -1.65027452e+00  1.64274013e+00\n",
            "  6.39609814e-01  4.39442486e-01  6.40575707e-01 -1.23431492e+00\n",
            " -2.07126355e+00 -3.36752057e-01 -1.10807037e+00 -1.87093151e+00\n",
            " -5.10886788e-01 -4.05953050e-01 -3.03553534e+00 -1.08222985e+00\n",
            "  6.87527955e-01  1.46222770e+00 -3.39230561e+00  2.39151216e+00\n",
            " -1.40015888e+00 -1.03500295e+00 -1.91767648e-01 -8.42000246e-01\n",
            " -6.82099283e-01 -1.09477079e+00 -9.04504359e-01 -2.11396024e-01\n",
            "  1.31402409e+00 -1.09247291e+00  3.73674124e-01 -1.02766442e+00\n",
            "  2.36571610e-01 -6.04301691e-01  2.44824097e-01 -7.38623917e-01\n",
            " -8.07547450e-01 -9.65652764e-01 -1.22435403e+00  9.48518932e-01\n",
            "  2.36743361e-01  1.94405901e+00 -1.81735981e+00 -1.75360274e+00\n",
            " -2.04885721e+00  5.70486069e-01 -1.34386456e+00  3.02295923e-01\n",
            " -5.66325903e-01 -3.89158517e-01  4.04986322e-01 -1.38960731e+00\n",
            " -5.39319396e-01  1.70696235e+00  3.54880728e-02 -8.79604459e-01\n",
            "  6.31394744e-01  2.34951973e+00 -2.99507833e+00 -1.38164532e+00\n",
            " -8.09166133e-01 -4.25935864e-01 -1.01080823e+00  3.03441472e-02]\n",
            "\n",
            "Label for this embedding: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gzAUAiY4QCCu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}